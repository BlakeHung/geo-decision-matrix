# Geo Decision Matrix

**æ··åˆæ¶æ§‹å¯¦æˆ°ï¼šSpark (CPU) + RAPIDS (GPU) çš„åœ°ç†æ±ºç­–æ”¯æ´ç³»çµ±**

## ğŸ“– å°ˆæ¡ˆç°¡ä»‹

é€™æ˜¯ä¸€å€‹å±•ç¤ºã€Œ**CPU + GPU æ··åˆæ¶æ§‹**ã€çš„çœŸå¯¦å·¥ç¨‹æ¡ˆä¾‹ï¼Œç”¨æ–¼è§£æ±ºåœ°åœ– API ä¾›æ‡‰å•†é·ç§»è©•ä¼°å•é¡Œã€‚

**æ ¸å¿ƒç†å¿µ**ï¼š
- **CPU (Apache Spark)** è™•ç†é‚è¼¯è¤‡é›œçš„ ETL æ¸…æ´—
- **Parquet** ä½œç‚ºé›¶æ‹·è²çš„é«˜é€Ÿå‚³è¼¸æ©‹æ¨‘
- **GPU (NVIDIA RAPIDS)** å°ˆæ³¨ç´”ç²¹çš„çŸ©é™£é‹ç®—

**æ•ˆèƒ½å°æ¯”**ï¼š
- âŒ Node.js å–®æ©Ÿï¼šæ•¸å°æ™‚ / OOM
- âŒ Dask Multi-GPUï¼ˆé›™å¡ï¼‰ï¼š420 ç§’ï¼ˆé€šè¨Š overheadï¼‰
- âœ… Spark + RAPIDSï¼ˆå–®å¡ï¼‰ï¼š**150 ç§’**ï¼ˆ2.8x åŠ é€Ÿï¼‰

---

## ğŸ—ï¸ æŠ€è¡“æ¶æ§‹

\`\`\`
Raw Data (500K GPS)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: Apache Spark (CPU)    â”‚
â”‚ - ETL æ¸…æ´—                       â”‚
â”‚ - Window Function               â”‚
â”‚ - Haversine è·é›¢è¨ˆç®—             â”‚
â”‚ åŸ·è¡Œæ™‚é–“: ~145 ç§’                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ (Parquet é›¶æ‹·è²)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: NVIDIA RAPIDS (GPU)   â”‚
â”‚ - K-Means èšé¡                   â”‚
â”‚ - æ¨™æº–åŒ– (StandardScaler)        â”‚
â”‚ åŸ·è¡Œæ™‚é–“: ~5 ç§’                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Decision Matrix API
\`\`\`

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### å‰ç½®éœ€æ±‚

- Docker + Docker Compose
- NVIDIA GPUï¼ˆæ”¯æ´ CUDA 11.8+ï¼‰
- NVIDIA Container Toolkit

### æ–¹æ³• 1ï¼šä½¿ç”¨ Dockerï¼ˆæ¨è–¦ï¼‰

\`\`\`bash
# 1. Clone å°ˆæ¡ˆ
git clone https://github.com/your-username/geo-decision-matrix.git
cd geo-decision-matrix

# 2. å•Ÿå‹• Docker å®¹å™¨
docker-compose up -d

# 3. é€²å…¥å®¹å™¨
docker exec -it geo_decision_matrix bash

# 4. åŸ·è¡Œå®Œæ•´ Pipeline
./run_pipeline.sh
\`\`\`

### æ–¹æ³• 2ï¼šæœ¬åœ°ç’°å¢ƒ

\`\`\`bash
# 1. å®‰è£ä¾è³´
pip install -r requirements.txt

# 2. å®‰è£ RAPIDSï¼ˆéœ€è¦ CUDA ç’°å¢ƒï¼‰
conda install -c rapidsai -c nvidia -c conda-forge \
    rapids=23.10 python=3.10 cudatoolkit=11.8

# 3. åŸ·è¡Œ Pipeline
./run_pipeline.sh
\`\`\`

---

## ğŸ“Š åŸ·è¡Œæµç¨‹è©³è§£

### Step 1: è³‡æ–™ç”Ÿæˆ

\`\`\`bash
python src/1_data_gen.py
\`\`\`

ç”Ÿæˆ 50 è¬ç­†æ¨¡æ“¬ GPS è»Œè·¡æ•¸æ“šï¼ˆ26 MB CSVï¼‰ã€‚

**é—œéµç‰¹è‰²**ï¼š
- å®šå‘æ³¨å…¥é«’æ•¸æ“šï¼ˆé‡ç–Šåº§æ¨™ã€ç¬é–“ç§»å‹•ï¼‰
- æ¸¬è©¦ç³»çµ±å° Edge Case çš„ç©©å¥æ€§

### Step 2: Spark ETL æ¸…æ´—

\`\`\`bash
python src/4_decision_matrix.py
\`\`\`

ä½¿ç”¨ Apache Spark é€²è¡Œ CPU å¯†é›†å‹è™•ç†ï¼š
- **Window Function**ï¼šè¨ˆç®—æ¯ä¸€æ­¥çš„ GPS è·é›¢
- **Haversine UDF**ï¼šåœ°çƒè¡¨é¢å…©é»è·é›¢å…¬å¼
- **ç•°å¸¸æª¢æ¸¬**ï¼šæ¨™è¨˜åœæ»¯é»ï¼ˆå€–å­˜è€…åå·®æŒ‡æ¨™ï¼‰

**è¼¸å‡º**ï¼š
- \`data/decision_result.parquet\`ï¼ˆGPU æœ€ä½³åŒ–æ ¼å¼ï¼‰
- \`data/decision_result.json\`ï¼ˆAPI ç›¸å®¹æ ¼å¼ï¼‰

**æŠ€è¡“äº®é»**ï¼š
\`\`\`python
# Parquet è¼¸å‡ºï¼ˆSnappy å£“ç¸®ï¼‰
decision_matrix.write.parquet(
    "data/decision_result.parquet",
    mode="overwrite",
    compression="snappy"  # GPU å‹å–„çš„å£“ç¸®æ ¼å¼
)
\`\`\`

**ç‚ºä½•ä½¿ç”¨ Parquetï¼Ÿ**
- âœ… **Coalesced Memory Access**ï¼ˆåˆä½µè¨˜æ†¶é«”å­˜å–ï¼‰
- âœ… **é›¶è§£ææˆæœ¬**ï¼ˆäºŒé€²åˆ¶ç›´è®€ï¼Œç„¡éœ€å­—ä¸²è½‰æ›ï¼‰
- âœ… **Memory Mapping**ï¼ˆmmap + CUDA Unified Memoryï¼‰

### Step 3: RAPIDS GPU èšé¡

\`\`\`bash
python src/6_ai_clustering.py
\`\`\`

ä½¿ç”¨ NVIDIA RAPIDS é€²è¡Œ GPU åŠ é€Ÿï¼š
- **cuDF**ï¼šGPU DataFrameï¼ˆé¡ä¼¼ Pandasï¼‰
- **cuML**ï¼šGPU æ©Ÿå™¨å­¸ç¿’ï¼ˆé¡ä¼¼ scikit-learnï¼‰

**æŠ€è¡“äº®é»**ï¼š
\`\`\`python
# GPU ç›´æ¥è®€å– Parquetï¼ˆé›¶æ‹·è²ï¼‰
gdf = cudf.read_parquet("data/decision_result.parquet")

# GPU K-Means èšé¡ï¼ˆ0.5 ç§’å®Œæˆï¼‰
kmeans = cuKMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X_scaled)
\`\`\`

**è‡ªå‹•é™ç´šæ©Ÿåˆ¶**ï¼š
- å„ªå…ˆä½¿ç”¨ GPU (cuDF + cuML)
- å¦‚æœ GPU ä¸å¯ç”¨ï¼Œè‡ªå‹•é™ç´šè‡³ CPU (Pandas + scikit-learn)

---

## â±ï¸ Benchmark æ¸¬è©¦

åŸ·è¡Œå®Œæ•´çš„æ•ˆèƒ½æ¸¬è©¦ï¼š

\`\`\`bash
./benchmark.sh
\`\`\`

**è¼¸å‡ºç¯„ä¾‹**ï¼š
\`\`\`
ğŸ“ˆ Benchmark Results
====================================
Total Execution Time: 150s

è©³ç´°æ‹†è§£:
â”œâ”€ Stage 1 (Spark ETL):   145s (97%)
â”‚  â”œâ”€ è³‡æ–™ç”Ÿæˆ + æ¸…æ´—
â”‚  â””â”€ Parquet è¼¸å‡º
â””â”€ Stage 2 (RAPIDS GPU):  5s (3%)
   â”œâ”€ Parquet è®€å– (0.8s)
   â”œâ”€ K-Means èšé¡ (0.5s)
   â””â”€ çµæœè¼¸å‡º (3.7s)
\`\`\`

---

## ğŸ“ å°ˆæ¡ˆçµæ§‹

\`\`\`
geo-decision-matrix/
â”œâ”€ src/
â”‚  â”œâ”€ 1_data_gen.py                    # è³‡æ–™ç”Ÿæˆå™¨
â”‚  â”œâ”€ 4_decision_matrix.py             # Spark ETL (CPU)
â”‚  â”œâ”€ 6_ai_clustering.py               # RAPIDS GPU (ä¸»è¦ç‰ˆæœ¬)
â”‚  â”œâ”€ 6_ai_clustering_distributed.py   # é›™ GPU ç‰ˆæœ¬ï¼ˆ3.1 å¤±æ•—æ¡ˆä¾‹ï¼‰
â”‚  â”œâ”€ 7_api_server.py                  # FastAPI æœå‹™
â”‚  â”œâ”€ 9_dashboard.py                   # Streamlit å„€è¡¨æ¿
â”‚  â””â”€ article_visualizations.py        # æŠ€è¡“æ–‡ç« åœ–è¡¨ç”Ÿæˆå™¨
â”œâ”€ doc/
â”‚  â”œâ”€ 3.1article_visual.md             # 3.1 æ–‡ç« è¦åŠƒï¼ˆç¡¬é«”é™åˆ¶ï¼‰
â”‚  â”œâ”€ 3.2_article_plan.md              # 3.2 æ–‡ç« è¦åŠƒï¼ˆæ¶æ§‹æ•‘è´–ï¼‰
â”‚  â””â”€ 3.2_article_content.md           # 3.2 å®Œæ•´æ–‡ç« ï¼ˆ3500å­—ï¼‰
â”œâ”€ outputs/
â”‚  â”œâ”€ article_topology_bottleneck.png  # ç¡¬é«”é »å¯¬ç‰†åœ–è¡¨
â”‚  â”œâ”€ article_hybrid_architecture.png  # æ··åˆæ¶æ§‹æµç¨‹åœ–
â”‚  â””â”€ article_benchmark_comparison.png # Benchmark å°æ¯”åœ–
â”œâ”€ data/                               # æ•¸æ“šç›®éŒ„ï¼ˆåŸ·è¡Œå¾Œç”Ÿæˆï¼‰
â”œâ”€ Dockerfile                          # RAPIDS + Spark å®¹å™¨
â”œâ”€ docker-compose.yml                  # Docker Compose é…ç½®
â”œâ”€ run_pipeline.sh                     # å®Œæ•´åŸ·è¡Œè…³æœ¬
â”œâ”€ benchmark.sh                        # æ•ˆèƒ½æ¸¬è©¦è…³æœ¬
â””â”€ README.md                           # æœ¬æ–‡ä»¶
\`\`\`

---

## ğŸ¯ é—œéµæŠ€è¡“é»

### 1. Window Functionï¼ˆSparkï¼‰

\`\`\`python
# è¨ˆç®—æ¯ä¸€æ­¥çš„ GPS ç§»å‹•è·é›¢
window_spec = Window.partitionBy("user_id").orderBy("timestamp")
df_lag = df.withColumn("prev_lat", F.lag("latitude").over(window_spec)) \
           .withColumn("prev_lon", F.lag("longitude").over(window_spec))
\`\`\`

### 2. Parquet åˆ—å¼å„²å­˜å„ªå‹¢

**CSV (Row-based)**ï¼š
\`\`\`
Record 1: [id, lat, lon, speed]
Record 2: [id, lat, lon, speed]
Record 3: [id, lat, lon, speed]
\`\`\`
GPU è®€å– \`speed\` æ¬„ä½æ™‚éœ€è¦è·³èºå­˜å–ï¼ˆ32 æ¬¡è¨˜æ†¶é«”è«‹æ±‚ï¼‰

**Parquet (Column-based)**ï¼š
\`\`\`
Column speed: [25.3, 42.1, 18.7, ...]ï¼ˆé€£çºŒå„²å­˜ï¼‰
\`\`\`
GPU è®€å– \`speed\` æ¬„ä½æ™‚ä¸€æ¬¡æ€§è¼‰å…¥ï¼ˆ1 æ¬¡è¨˜æ†¶é«”è«‹æ±‚ï¼‰

**æ•ˆèƒ½å·®ç•°**ï¼š32 å€åŠ é€Ÿ

### 3. GPU è‡ªå‹•é™ç´šæ©Ÿåˆ¶

\`\`\`python
if GPU_AVAILABLE:
    try:
        # å˜—è©¦ GPU é‹ç®—
        gdf = cudf.read_parquet("data.parquet")
        kmeans = cuKMeans(n_clusters=3)
    except Exception as e:
        # è‡ªå‹•é™ç´šè‡³ CPU
        GPU_AVAILABLE = False
        return perform_clustering(df)
else:
    # CPU Fallback
    df = pd.read_parquet("data.parquet")
    kmeans = KMeans(n_clusters=3)
\`\`\`

---

## ğŸ“ˆ è¦–è¦ºåŒ–åœ–è¡¨

å°ˆæ¡ˆåŒ…å« 3 å¼µé«˜å“è³ªæŠ€è¡“åœ–è¡¨ï¼ˆ\`outputs/\` ç›®éŒ„ï¼‰ï¼š

### 1. ç¡¬é«”é »å¯¬ç‰†
![Topology Bottleneck](outputs/article_topology_bottleneck.png)

å±•ç¤º NVLink (900 GB/s) vs PCIe Detour (12 GB/s) çš„å°æ¯”ã€‚

### 2. æ··åˆæ¶æ§‹æµç¨‹
![Hybrid Architecture](outputs/article_hybrid_architecture.png)

å®Œæ•´çš„ CPU â†’ Parquet â†’ GPU è³‡æ–™æµç¨‹ã€‚

### 3. Benchmark å°æ¯”
![Benchmark](outputs/article_benchmark_comparison.png)

ç¶ è‰² 150s (å–® GPU) vs ç´…è‰² 420s (é›™ GPU)ï¼Œè­‰æ˜ã€Œå°‘å³æ˜¯å¤šã€ã€‚

---

## ğŸ› ï¸ é€²éšä½¿ç”¨

### å•Ÿå‹•å®Œæ•´æœå‹™

\`\`\`bash
# 1. å•Ÿå‹• API æœå‹™
python src/7_api_server.py
# è¨ªå•: http://localhost:9090

# 2. å•Ÿå‹• Streamlit å„€è¡¨æ¿
streamlit run src/9_dashboard.py
# è¨ªå•: http://localhost:8501

# 3. æŸ¥çœ‹ Spark UIï¼ˆåŸ·è¡Œ ETL æ™‚ï¼‰
# è¨ªå•: http://localhost:4040
\`\`\`

### ç”Ÿæˆæ–‡ç« åœ–è¡¨

\`\`\`bash
# ç”ŸæˆæŠ€è¡“æ–‡ç« æ‰€éœ€çš„è¦–è¦ºåŒ–åœ–è¡¨
python src/article_visualizations.py
\`\`\`

è¼¸å‡ºï¼š
- \`outputs/article_topology_bottleneck.png\`
- \`outputs/article_hybrid_architecture.png\`
- \`outputs/article_benchmark_comparison.png\`

---

## ğŸ› å¸¸è¦‹å•é¡Œ

### Q1: åŸ·è¡Œæ™‚å‡ºç¾ "CUDA out of memory"

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
\`\`\`python
# æ¸›å°‘æ•¸æ“šé‡æˆ–å•Ÿç”¨ RAPIDS Managed Memory
import rmm
rmm.reinitialize(managed_memory=True)
\`\`\`

### Q2: WSL 2 ç’°å¢ƒé›™ GPU éŒ¯èª¤

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
\`\`\`bash
# ä½¿ç”¨å–® GPU ç‰ˆæœ¬
export CUDA_VISIBLE_DEVICES=0
python src/6_ai_clustering.py
\`\`\`

æˆ–ä½¿ç”¨ WSL å®‰å…¨ç‰ˆæœ¬ï¼š
\`\`\`bash
python src/6_ai_clustering_wsl_safe.py
\`\`\`

### Q3: Spark æ‰¾ä¸åˆ° Java

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
\`\`\`bash
# å®‰è£ OpenJDK
apt-get update && apt-get install -y openjdk-11-jdk

# è¨­å®šç’°å¢ƒè®Šæ•¸
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
\`\`\`

---

## ğŸ“š ç›¸é—œæ–‡ç« 

- **3.1 ç¡¬é«”é™åˆ¶ç¯‡**ï¼šç‚ºä½•é›™ GPU åè€Œæ›´æ…¢ï¼Ÿï¼ˆ\`doc/3.1article_visual.md\`ï¼‰
- **3.2 è»Ÿé«”æ•‘è´–ç¯‡**ï¼šæ··åˆæ¶æ§‹å¯¦æˆ°ï¼ˆ\`doc/3.2_article_content.md\`ï¼‰

---

## ğŸ¤ è²¢ç»

æ­¡è¿æäº¤ Issue æˆ– Pull Requestï¼

## ğŸ“„ æˆæ¬Š

MIT License

---

## ğŸ™ è‡´è¬

- **Apache Spark**ï¼šåˆ†æ•£å¼ ETL æ¡†æ¶
- **NVIDIA RAPIDS**ï¼šGPU åŠ é€Ÿè³‡æ–™ç§‘å­¸
- **PyArrow**ï¼šé«˜æ•ˆçš„åˆ—å¼å„²å­˜
- **Docker**ï¼šå®¹å™¨åŒ–éƒ¨ç½²

---

**é—œéµå­—**ï¼šHybrid Architecture, Spark RAPIDS, Parquet GPU, Data Engineering, ETL Pipeline, cuDF cuML, Memory Mapping, Coalesced Access

**å°ˆæ¡ˆä½œè€…**ï¼šBlake  
**æœ€å¾Œæ›´æ–°**ï¼š2026-01-08
