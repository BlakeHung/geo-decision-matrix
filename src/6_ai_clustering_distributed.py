import os
import time
import numpy as np
import pandas as pd
import warnings

# --- ğŸ”¥ WSL 2 é›™å¡ç©©å®šæ€§è¨­å®š ---
# 1. é—œé–‰ P2P (é¿å… Error 201)
os.environ["NCCL_P2P_DISABLE"] = "1"

# 2. å¼·åˆ¶ Dask èµ° TCP (é¿å… Segmentation Fault)
os.environ["DASK_CUDA_INTERFACE"] = "eth0"
os.environ["DASK_DISTRIBUTED__COMM__TIMEOUTS__CONNECT"] = "60s"
# ç¢ºä¿ UCX ç›¸é—œè®Šæ•¸ä¸æœƒå¹²æ“¾ TCP æ¨¡å¼
os.environ["UCX_TLS"] = "tcp,cuda_copy,sockcm" 
os.environ["UCX_SOCKADDR_TLS_PRIORITY"] = "sockcm"

# 3. é—œé–‰æ´©æ¼æª¢æŸ¥è­¦å‘Š
os.environ["DASK_CUDA_LEAK_CHECK"] = "0"

try:
    import cudf
    import dask.dataframe as dd
    import dask_cudf
    from dask.distributed import Client
    from dask_cuda import LocalCUDACluster
    from cuml.dask.cluster import KMeans as DaskKMeans
    RAPIDS_AVAILABLE = True
    print("ğŸš€ [System] Dask-CUDA æ¨¡çµ„è¼‰å…¥æˆåŠŸï¼")
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ Dask å¥—ä»¶: {e}")
    exit(1)

# è¨­å®šæª”æ¡ˆè·¯å¾‘
INPUT_FILE = 'data/decision_result.json'
OUTPUT_FILE = 'data/clustered_result.json'

def generate_mock_data(n_rows=10000):
    """ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š"""
    print(f"âš ï¸ ç”Ÿæˆ {n_rows} ç­†æ¨¡æ“¬æ•¸æ“š...")
    df = pd.DataFrame({
        "driver_id": [f"D_{i}" for i in range(n_rows)],
        "total_km": np.random.uniform(5, 50, n_rows),
        "average_speed": np.random.uniform(10, 80, n_rows),
        "stuck_count": np.random.randint(0, 10, n_rows).astype(float)
    })
    return df

def main():
    if not RAPIDS_AVAILABLE: return

    # --- 1. å•Ÿå‹•é›™å¡æŒ‡æ®å®˜ ---
    print("âš¡ æ­£åœ¨åˆå§‹åŒ– Dask CUDA Cluster (ç´” TCP æ¨¡å¼)...")
    try:
        # [é—œéµä¿®æ­£] å¾¹åº•é—œé–‰æ‰€æœ‰åŠ é€Ÿå™¨ï¼Œåªç•™ TCP
        cluster = LocalCUDACluster(
            rmm_managed_memory=True,   # å¿…é ˆé–‹ (WSL è¨˜æ†¶é«”ç®¡ç†)
            threads_per_worker=1,
            protocol="tcp",            # å¼·åˆ¶ TCP
            enable_tcp_over_ucx=False, # âŒ é—œé–‰ UCX
            enable_infiniband=False,   # âŒ é—œé–‰ InfiniBand
            enable_nvlink=False,       # âŒ é—œé–‰ NVLink (WSL ä¸æ”¯æ´)
            jit_unspill=False
        )
        client = Client(cluster)
        print(f"âœ… é›™å¡å¢é›†å•Ÿå‹•æˆåŠŸï¼")
        
        workers = client.scheduler_info()['workers']
        print(f"   Workers: {len(workers)} (ç›®æ¨™: 2)")
        
    except Exception as e:
        print(f"âŒ é›™å¡å•Ÿå‹•å¤±æ•—: {e}")
        return

    # --- 2. æº–å‚™æ•¸æ“š ---
    start_time = time.time()
    pdf = generate_mock_data(50000) # 5è¬ç­†æ¸¬è©¦
    
    # --- 3. å°‡æ•¸æ“šåˆ†ç™¼çµ¦å…©å¼µé¡¯å¡ ---
    print("âš¡ [GPU] æ­£åœ¨å°‡æ•¸æ“šåˆ‡å‰²ä¸¦å‚³é€è‡³ GPU 0 å’Œ GPU 1...")
    
    # CPU Pandas -> Dask CPU -> Dask GPU
    ddf_cpu = dd.from_pandas(pdf, npartitions=2)
    ddf_gpu = ddf_cpu.map_partitions(cudf.DataFrame.from_pandas)

    features = ['total_km', 'average_speed', 'stuck_count']
    X_dask = ddf_gpu[features]

    # --- 4. é›™å¡åŒæ­¥é‹ç®— ---
    print("âš¡ [GPU] é–‹å§‹ä¸¦è¡Œ K-Means èšé¡...")
    
    kmeans = DaskKMeans(n_clusters=3, random_state=42)
    kmeans.fit(X_dask)
    
    ddf_gpu['cluster'] = kmeans.predict(X_dask)

    # --- 5. å½™æ•´çµæœ ---
    print("âš¡ [Result] æ­£åœ¨å½™æ•´çµæœ...")
    final_df = ddf_gpu.compute().to_pandas()
    
    duration = time.time() - start_time
    print(f"ğŸš€ [Done] é›™å¡é‹ç®—å®Œæˆï¼ç¸½è€—æ™‚: {duration:.4f} ç§’")
    print(f"ğŸ“Š è™•ç†ç¸½ç­†æ•¸: {len(final_df)}")

    # é—œé–‰é€£ç·š
    client.close()
    cluster.close()

if __name__ == "__main__":
    main()