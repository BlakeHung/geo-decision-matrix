import os
import time
import numpy as np
import pandas as pd

# --- ğŸ”¥ [æ ¸å¿ƒé…ç½®] é‡å°ç„¡ NVLink çš„é›™å¡ç’°å¢ƒ ---
# æ—¢ç„¶æ²’æœ‰ NVLinkï¼Œæˆ‘å€‘å¿…é ˆå¾¹åº•åˆ‡æ–·æ‰€æœ‰é¡¯å¡é–“çš„ç›´æ¥é€šè¨Š
os.environ["NCCL_P2P_DISABLE"] = "1"
os.environ["NCCL_P2P_LEVEL"] = "0"    # å¼·åˆ¶ä¸ä½¿ç”¨ P2P
os.environ["NCCL_IB_DISABLE"] = "1"

# å¾¹åº•ç¦ç”¨ UCXï¼Œæ”¹ç”¨ Dask å…§å»ºçš„ Tornado TCP
# é€™æ˜¯é¿é–‹ Segmentation Fault (UCX å´©æ½°) çš„æœ€çµ‚æ‰‹æ®µ
os.environ["DASK_UCX__CUDA_COPY"] = "False"
os.environ["DASK_UCX__TCP"] = "False"

try:
    import cudf
    import dask.dataframe as dd
    import dask_cudf
    from dask.distributed import Client
    from dask_cuda import LocalCUDACluster
    from cuml.dask.cluster import KMeans as DaskKMeans
    RAPIDS_AVAILABLE = True
    print("ğŸš€ [System] RAPIDS æ¨¡çµ„è¼‰å…¥æˆåŠŸï¼")
except ImportError as e:
    print(f"âŒ ç¼ºå°‘å¥—ä»¶: {e}")
    exit(1)

def main():
    # --- 1. å•Ÿå‹•é›™å¡æŒ‡æ®å®˜ (ä¸ä½¿ç”¨ UCX) ---
    print("âš¡ æ­£åœ¨åˆå§‹åŒ– Dask CUDA Cluster (No-NVLink å®‰å…¨æ¨¡å¼)...")
    try:
        # protocol="tcp" é…åˆ enable_tcp_over_ucx=False 
        # æœƒå¼·åˆ¶è®“ Dask èµ°æœ€ç©©å®šçš„ Python TCP é€šè¨Š
        cluster = LocalCUDACluster(
            rmm_managed_memory=True,   # WSL 2 å¿…é–‹
            threads_per_worker=1,
            protocol="tcp",            # èµ° TCP é€šè¨Š
            enable_tcp_over_ucx=False, # ç¦ç”¨ UCX
            enable_nvlink=False,       # ç¦ç”¨ NVLink (æ‚¨å·²ç¢ºèªæ²’æœ‰)
            enable_infiniband=False    # ç¦ç”¨ InfiniBand
        )
        client = Client(cluster)
        print(f"âœ… é›™å¡å¢é›†å•Ÿå‹•æˆåŠŸï¼")
        
        workers = client.scheduler_info()['workers']
        print(f"   Workers: {len(workers)} (æ‡‰è©²æ˜¯ 2)")
    except Exception as e:
        print(f"âŒ é›™å¡å•Ÿå‹•å¤±æ•—: {e}")
        return

    # --- 2. æº–å‚™æ•¸æ“š ---
    start_time = time.time()
    # æ—¢ç„¶æœ‰å…©å¼µ 3090 (48GB VRAM)ï¼Œæˆ‘å€‘æŠŠæ•¸æ“šé‡é–‹å¤§åˆ° 10 è¬ç­†æ¸¬è©¦
    print("âš ï¸ ç”Ÿæˆ 100,000 ç­†æ¨¡æ“¬æ•¸æ“šä»¥æ¸¬è©¦é›™å¡ç®—åŠ›...")
    pdf = pd.DataFrame({
        "driver_id": [f"D_{i}" for i in range(100000)],
        "total_km": np.random.uniform(5, 50, 100000),
        "average_speed": np.random.uniform(10, 80, 100000),
        "stuck_count": np.random.randint(0, 10, 100000).astype(float)
    })
    
    # --- 3. å°‡æ•¸æ“šåˆ†ç™¼çµ¦å…©å¼µé¡¯å¡ ---
    print("âš¡ [GPU] æ­£åœ¨å°‡æ•¸æ“šåˆ‡å‰²ä¸¦åˆ†ç™¼è‡³å…©å¼µ 3090...")
    
    # å°‡æ•¸æ“šåˆ‡æˆå…©ä»½ï¼ŒDask æœƒè‡ªå‹•æŠŠå…¶ä¸­ä¸€ä»½ä¸Ÿåˆ° GPU 0ï¼Œå¦ä¸€ä»½ä¸Ÿåˆ° GPU 1
    ddf_cpu = dd.from_pandas(pdf, npartitions=2)
    ddf_gpu = ddf_cpu.map_partitions(cudf.DataFrame.from_pandas)

    features = ['total_km', 'average_speed', 'stuck_count']
    X_dask = ddf_gpu[features]

    # --- 4. é›™å¡åŒæ­¥é‹ç®— ---
    print("âš¡ [GPU] é–‹å§‹ä¸¦è¡Œ K-Means èšé¡é‹ç®—...")
    
    # é€™è£¡ cuML æœƒåœ¨èƒŒæ™¯åŒæ­¥å…©å€‹ GPU çš„èšé¡ä¸­å¿ƒé»
    kmeans = DaskKMeans(n_clusters=3, random_state=42)
    kmeans.fit(X_dask)
    
    ddf_gpu['cluster'] = kmeans.predict(X_dask)

    # --- 5. å½™æ•´çµæœ ---
    print("âš¡ [Result] æ­£åœ¨å¾é¡¯å¡å›æ”¶çµæœ...")
    final_df = ddf_gpu.compute().to_pandas()
    
    duration = time.time() - start_time
    print(f"ğŸš€ [Done] é›™å¡é‹ç®—å®Œæˆï¼ç¸½è€—æ™‚: {duration:.4f} ç§’")
    print(f"ğŸ“Š ç¸½è™•ç†ç­†æ•¸: {len(final_df)}")

    client.close()
    cluster.close()

if __name__ == "__main__":
    main()