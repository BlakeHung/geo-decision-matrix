import os
import json
import torch
import pandas as pd
from fastapi import FastAPI, HTTPException
from transformers import pipeline

# --- ğŸ”¥ ç’°å¢ƒèˆ‡ç¡¬é«”é…ç½® ---
os.environ["CUDA_VISIBLE_DEVICES"] = "0"  # å¼·åˆ¶é–å®š x16 é¡¯å¡
DATA_FILE = 'data/clustered_result.json'

app = FastAPI(title="Geo-Decision AI Integrated System")

# --- ğŸš€ è¼‰å…¥ GPU AI æ¨¡å‹ (NLP é¡§å•) ---
print("â³ æ­£åœ¨åŠ è¼‰ AI æ±ºç­–æ¨¡å‹è‡³ RTX 3090 (GPU 0)...")
try:
    # ä½¿ç”¨å…·å‚™è¡Œç‚ºåˆ¤æ–·èƒ½åŠ›çš„åˆ†ææ¨¡å‹
    analyzer = pipeline(
        "sentiment-analysis", 
        model="distilbert-base-uncased-finetuned-sst-2-english",
        device=0 if torch.cuda.is_available() else -1
    )
    print("âœ… GPU AI æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
except Exception as e:
    print(f"âš ï¸ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    analyzer = None

@app.get("/")
def home():
    return {
        "status": "online", 
        "engine": "FastAPI + Transformers (GPU)",
        "endpoints": ["/results", "/ai/analyze_risks"]
    }

@app.get("/results")
def get_all_results():
    """ç²å–åˆ†ç¾¤ JSON åŸå§‹è³‡æ–™"""
    if not os.path.exists(DATA_FILE):
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°æ•¸æ“šï¼Œè«‹å…ˆåŸ·è¡Œ 6_ai_clustering.py")
    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

@app.get("/ai/analyze_risks")
def analyze_risks():
    """ä½¿ç”¨ GPU å°é«˜é¢¨éšªå¸æ©Ÿé€²è¡Œæ™ºæ…§åŒ–åˆ†æèˆ‡å»ºè­°"""
    if not os.path.exists(DATA_FILE):
        raise HTTPException(status_code=404, detail="è³‡æ–™ä¸å­˜åœ¨")
    
    df = pd.read_json(DATA_FILE)
    
    # --- æ™ºæ…§ç¯©é¸æ©Ÿåˆ¶ ---
    # å„ªå…ˆæŠ“å–æ¨™ç±¤åŒ…å« "Risk" æˆ– "ç´…è‰²" çš„å¸æ©Ÿ
    risky_drivers = df[df['label'].str.contains("Risk|ç´…è‰²", case=False, na=False)].head(5)
    
    # å¦‚æœæ¨™ç±¤åŒ¹é…ä¸åˆ°ï¼Œå‰‡è‡ªå‹•æŠ“å–æ™‚é€Ÿæœ€ä½çš„å‰ 3 å
    if risky_drivers.empty:
        print("âš ï¸ æ¨™ç±¤æœªåŒ¹é…ï¼Œæ”¹ç‚ºæŠ“å–æ™‚é€Ÿæœ€ä½çš„å¸æ©Ÿé€²è¡Œåˆ†æ...")
        risky_drivers = df.nsmallest(3, 'average_speed')

    results = []
    if analyzer:
        for _, driver in risky_drivers.iterrows():
            # å»ºç«‹æè¿°æ–‡æœ¬ä¾› AI åˆ†æ
            status_text = f"Driver {driver['driver_id']} is traveling at {driver['average_speed']:.1f} km/h with {driver['stuck_count']} stops."
            
            # åŸ·è¡Œ GPU æ¨è«–
            inference = analyzer(status_text)[0]
            sentiment = inference['label']
            
            # å°‡ AI æƒ…æ„Ÿåˆ†æè½‰åŒ–ç‚ºå…·é«”çš„ç®¡ç†å»ºè­°
            management_advice = "ğŸš¨ å»ºè­°ç«‹å³é€²è¡Œå®‰å…¨é¢è«‡ï¼Œå¯èƒ½å­˜åœ¨é•è¦æˆ–ç–²å‹é§•é§›ã€‚" if sentiment == "NEGATIVE" else "ğŸŸ¢ è¡¨ç¾å°šå¯ï¼Œå»ºè­°æŒçºŒè§€å¯Ÿè·¯æ³å½±éŸ¿ã€‚"
            
            results.append({
                "driver_id": driver['driver_id'],
                "label": driver['label'],
                "speed": f"{driver['average_speed']:.2f} km/h",
                "ai_sentiment": sentiment,
                "management_advice": management_advice
            })
    
    return {
        "status": "success",
        "processed_by": "NVIDIA RTX 3090",
        "analysis_count": len(results),
        "ai_insights": results
    }

if __name__ == "__main__":
    import uvicorn
    # çµ±ä¸€ä½¿ç”¨ 8000 ç«¯å£
    uvicorn.run(app, host="0.0.0.0", port=8000)