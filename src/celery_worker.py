import os
import time
import torch
from celery import Celery
from transformers import pipeline

# ==========================================
# 1. é…ç½®è¨­å®š (Configuration)
# ==========================================
# Redis é€£ç·šè¨­å®š (Docker å…§éƒ¨ localhost å³å¯ï¼Œå› ç‚º Redis èˆ‡ Worker åœ¨åŒå€‹å®¹å™¨)
CELERY_BROKER_URL = 'redis://localhost:6379/0'
CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'

# åˆå§‹åŒ– Celery æ‡‰ç”¨
# 'geo_ai_worker' æ˜¯é€™å€‹æ‡‰ç”¨ç¨‹å¼çš„åç¨±
app = Celery('geo_ai_worker', broker=CELERY_BROKER_URL, backend=CELERY_RESULT_BACKEND)

# ==========================================
# 2. æ¨¡å‹ç†±å•Ÿå‹• (Global Model Loading)
# ==========================================
# é—œéµå„ªåŒ–ï¼šåœ¨ Global Scope è¼‰å…¥æ¨¡å‹ï¼Œç¢ºä¿ Worker å•Ÿå‹•æ™‚åªè¼‰å…¥ä¸€æ¬¡ã€‚
# é€™é¿å…äº†æ¯æ¬¡ä»»å‹™éƒ½é‡æ–°è®€å–æ¨¡å‹ (Cold Start) çš„å·¨å¤§é–‹éŠ·ã€‚

print("â³ [System] æ­£åœ¨åˆå§‹åŒ– AI æ¨¡å‹ (Warm Start)...")

try:
    # æª¢æŸ¥ GPU æ˜¯å¦å¯ç”¨
    device_id = 0 if torch.cuda.is_available() else -1
    device_name = torch.cuda.get_device_name(0) if device_id != -1 else "CPU"
    
    # ä½¿ç”¨ HuggingFace Pipeline è¼‰å…¥æ¨¡å‹
    # é€™è£¡ä½¿ç”¨ distilbert åšæƒ…æ„Ÿåˆ†æï¼Œæ¨¡æ“¬ã€Œé§•é§›è¡Œç‚ºé¢¨éšªè©•ä¼°ã€
    risk_analyzer = pipeline(
        "sentiment-analysis", 
        model="distilbert-base-uncased-finetuned-sst-2-english",
        device=device_id
    )
    print(f"âœ… [System] æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
    print(f"ğŸš€ [Hardware] é‹è¡Œè£ç½®: {device_name}")

except Exception as e:
    print(f"âŒ [System] æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    risk_analyzer = None

# ==========================================
# 3. å®šç¾©ä»»å‹™ (The Task)
# ==========================================
@app.task(bind=True)
def analyze_driver_risk(self, driver_id, speed, stuck_count):
    """
    é€™æ˜¯ä¸€å€‹è¢« Celery ç®¡ç†çš„éåŒæ­¥ä»»å‹™ã€‚
    å®ƒæ¥æ”¶é§•é§›æ•¸æ“šï¼Œé€²è¡Œ AI æ¨è«–ï¼Œä¸¦è¿”å› JSON çµæœã€‚
    """
    start_time = time.time()
    
    # 1. æ§‹å»º Prompt (å°‡æ•¸å­—è½‰ç‚ºèªæ„)
    # å‡è¨­ï¼šå¡ä½æ¬¡æ•¸å¤šä¸”é€Ÿåº¦æ…¢ -> è² é¢ (High Risk)
    context_text = f"Driver {driver_id} is driving at {speed} km/h and got stuck {stuck_count} times."
    
    try:
        # 2. åŸ·è¡Œ AI æ¨è«– (Inference)
        if risk_analyzer:
            # æ¨¡å‹è¼¸å‡ºç¯„ä¾‹: [{'label': 'NEGATIVE', 'score': 0.99}]
            result = risk_analyzer(context_text)[0]
            label = result['label']
            confidence = result['score']
            
            # è½‰æ›ç‚ºæ¥­å‹™é‚è¼¯
            risk_level = "High Risk" if label == "NEGATIVE" else "Safe"
        else:
            # Fallback (å¦‚æœæ¨¡å‹æ²’è¼‰å…¥æˆåŠŸ)
            risk_level = "Unknown (Model Error)"
            confidence = 0.0

        # 3. è¨ˆç®—è™•ç†æ™‚é–“
        process_time = time.time() - start_time
        
        # 4. å›å‚³çµæ§‹åŒ–è³‡æ–™ (é€™æœƒè¢«å­˜å› Redis)
        return {
            "driver_id": driver_id,
            "risk_level": risk_level,
            "ai_confidence": round(confidence, 4),
            "process_time": f"{process_time:.4f}s",
            "processor": f"Celery Worker on {device_name}"
        }

    except Exception as e:
        return {
            "driver_id": driver_id,
            "error": str(e),
            "status": "Failed"
        }